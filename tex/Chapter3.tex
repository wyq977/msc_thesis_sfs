\chapter{Infinite-width Barron spaces}
\label{ch:infinite}

The main goal of this chapter is to construct and identify the function spaces
associated with 2NN of different activation functions including Heaviside
function and ReLU function family. To paraphrase
\cite{carageaNeuralNetworkApproximation2022}, functions are in
\textit{infinite-width Barron spaces} if and only if they admit a integral
representation, and they could be well approximated by 2NN. By ``well
approximation'', the approximation error rate is of the order $\bigO(n^{-1/2})$
when $n$ is the number of nodes. In contrast to the Fourier-analytic Barron
spaces in chapter \ref{ch:fourier}, these spaces are more dependent on the
choice of activation functions and certainly do not cover all conceivable
functions that has a integral representation. 

In section \ref{sec:construction_of_infinite_width}, we define the norm and
integral condition for the functions in infinite-width Barron spaces, followed
by the construction of these function spaces. The elementary properties of these
spaces are included for completeness. Section
\ref{sec:approximation_in_infinite_width} details the approximation error rate
for functions in these space associated in $\lp{2}$ and $\lp{\infty}$. Section
\ref{sec:infintie_width_variation_space} connects the the notion of the
variation space and variation norm to infinite-width Barron space through the
construction of compact dictionaries. Next, the relationships between
infinite-width Barron spaces and Fourier-analytic Barron space are examined in
section \ref{sec:diff_barron_spaces}.

This chapter aims to provide a concise summary of various well-known results
concerning the approximation properties of 2NN with the ReLU activation function
family, and we recommend the work by
\cite{eMathematicalUnderstandingNeural2020,bernerModernMathematicsDeep2021} for
a comprehensive review.

% sparsity-inducing norm ? in bach 2017 paper.

\section{Construction of infinite-width Barron spaces}
\label{sec:construction_of_infinite_width}

This section introduces the infinite-width Barron space and its elementary
properties, which is mostly based on \cite{eBarronSpaceFlowinduced2021} unless
stated otherwise.

Let $U$ be a nonempty and bounded domain in $\R^d$. For functions $f: U \to
\mathbb{R}$, we consider those that admit the following integral representation:

\begin{equation}
    \label{eq:barron_represent}
    f(x) = \int_{\Omega} a \sigma(b\tr x + c) \mu(da, db, dc), \quad 
    x \in U, a,c \in \R, b \in \R^d.
\end{equation}

Let $\Omega = \R^1 \times \R^d \times \R^1$ and $\Sigma_{\Omega}$ be the
$\sigma$-algebra on $\Omega$. We define an integral condition for $f$ w.r.t. a
a probability distribution $\mu$ on $(\Omega, \Sigma_\Omega)$
\begin{align}
    r(f, \mu, p)
    &= \Big(\int_{\R^d} \abs{a}^p  (\abs{b} + \abs{c})^p \,d\mu(a,b,c)\Big)^{1/p} \\
    &= \Big(\ERWi{\mu}{\abs{a}^p  (\abs{b} + \abs{c})^p}\Big)^{1/p},
    \quad 1 \leq p \leq +\infty.
\end{align}

$\Omega = \mathbb{R}^1 \times \mathbb{R}^d \times \mathbb{R}^1$ and
$\Sigma_\Omega$ is a Borel $\sigma$-algebra on $\Omega$ and $\sigma(\cdot)$ is
the ReLU activation function.

We consider special case where the ReLU function is replaced by the Heaviside
function.

\begin{definition}[Heaviside function]
    \label{eq:heaviside}
    \begin{equation}
        H(x) = 
        \begin{cases}
            1 \quad x > 0,\\
            0 \quad x \leq 0    
        \end{cases}
    \end{equation}
\end{definition}


Similarly, we consider functions $f$ that admit the representation below
\begin{equation}
    \label{eq:heaviside_represent}
    f(x) = \int_{\Omega} a H(b\tr x + c) \mu(da, db, dc), \quad x \in U.
\end{equation}

Accordingly, we define an integral condition for that particular $\mu$ where
\eqref{eq:heaviside_represent} holds
\begin{align}
    r(f,\mu, H)
    = \int_{\Omega} \abs{a}\,d\mu(a,b,c) = \ERWi{\mu}{\abs{a}}
\end{align}

The integral representation above can be seen as a continuum analogy of the 2NN
with $n$ hidden nodes:

\begin{equation}
    f_n(x, \Theta) := \frac{1}{n}
    \sum_{j=1}^n a_j 
        \sigma(b\tr x + c_j), 
    \quad \Theta = \{(a_j, b_j, c_j), \ j = 1, \dots, n\}.
\end{equation}

\begin{definition}[Barron norm] For a function $f$ that admits the integral
    representation in \eqref{eq:barron_represent}, its Barron norm is defined as
    \begin{equation}\label{eq:barron_norm}
        \barronnorm{f}{p} := \inf_{\rho} \Big(\ERWi{\rho}{\abs{a}^p 
        (\abs{b} + \abs{c})^p}\Big)^{1/p},
        \quad 1 \leq p \leq \infty.
    \end{equation}
    % where \begin{equation*} \Theta_f = \left\{ (a, \pi) \mid f(x) =
    % \int_{space} a(w) \sigma(\langle w, x \rangle)\dd{\pi(w)} \right\}.
    % \end{equation*}
\end{definition}

The infimum is taken over all probability distribution where
\eqref{eq:barron_represent} holds for all $x \in U$. When $p = \infty$, the
Barron norm reads
\begin{equation}
    \label{eq:barron_infinite_norm}
    \barronnorm{f}{\infty} :=
    \inf_{\rho} \max_{a, b, c \in \supp(\rho)} \abs{a} (\abs{b} + \abs{c}).
\end{equation}

Similarly, we can define a norm associated with Heaviside function where the
infimum is taken for all measure $\rho$ where \eqref{eq:heaviside_represent}
holds
\begin{equation}
    \label{def:heaviside_norm}
    \norm{f}_{\mcal{B}_H} = \inf_{\rho} \ERWi{\rho}{\abs{a}},
    \quad 1 \leq p \leq +\infty.
\end{equation}

\begin{definition}[Infinite-width Barron space]
    \label{def:barron_space}
    Let $U$ be a nonempty bounded domain in $\R^d$. For functions that admit the
    integral representation in \eqref{eq:barron_represent}, the infinite-width
    Barron space with an order of $1 \leq p \leq \infty$ is
    \begin{equation}
        \label{eq:barron_space}
        \mcal{B}_p(U) = \Bigg\{
            f: U \to \R : \exists\, \mu \in \Sigma_{\Omega}: 
            r(f, \mu, p) < \infty \textnormal{ and }
            \forall\, x \in U, f(x) = \int_{\Omega} a \sigma(b\tr x + c) \mu(da, db, dc)
        \Bigg\}.
    \end{equation}
\end{definition}

A normed space can be defined for those associated with Heaviside function.

\begin{definition}[Classical Barron space]
    \label{def:heaviside_space}
    Let $U$ be a nonempty unbounded domain in $\R^d$. For functions that admit
    the integral representation in \eqref{eq:heaviside_represent}, the
    infinite-width Barron space associated with Heaviside function is
    \begin{equation}
        \label{eq:heaviside_space}
        \mcal{B}_H(U) = \Bigg\{
            f: U \to \R : \exists\, \mu \in \Sigma_{\Omega}:
            r(f, \mu, H) < \infty \textnormal{ and }
            \forall\, x \in U, f(x) = \int_{\Omega} a H(b\tr x + c) \mu(da, db, dc)
        \Bigg\}.
    \end{equation}
\end{definition}

Barron spaces are denoted by $\mathcal{B}_p$~\footnote{
    Going forward, we will simplify $\mcal{B}_{\mcal{F}, s}(U)$, $\mcal{B}_p(U)$ 
    and $\mcal{B}_H(U)$ as $\mcal{B}_{\mcal{F}, S}$, $\mcal{B}_p$ and 
    $\mcal{B}_H$ to avoid cluttering the notations when $U$ is a bounded domain
    in $\R^d$.
}, consist of all the functions whose $r(f, \mu, p)$ is finite for a measure 
$\mu \in \Sigma_{\Omega}$.

\begin{proposition}
    By the definition of Barron norm, it is easy to see that

    \begin{equation}
        \mathcal{B}_{\infty} \subset \cdots \subset \mathcal{B}_{2} 
        \subset \mathcal{B}_1.
    \end{equation}
\end{proposition}


% https://ocw.mit.edu/courses/18-125-measure-and-integration-fall-2003/6f21af6c40de1eccd70349bd3a3b0095_18125_lec17.pdf

\begin{proof}

The idea is similar to the inclusion of $L_p$, $L_q$ space.

Applying HÃ¶lder's inequality, for any $1 \leq p \leq q < \infty$

\begin{align*}
    \int \abs{a}^p (\abs{b} + \abs{c})^p \,d\rho
    & = \int \abs{a}^p (\abs{b} + \abs{c})^p \cdot 1 \,d\rho \\
    & \leq \Big(
        \int \abs{a}^{p \cdot q/p} (\abs{b} + \abs{c})^{p \cdot q/p} \,d\rho
    \Big)^{p/q} \Big(\int \,d\rho\Big)^{1-p/q} \\
    & = \Big(
        \int \abs{a}^q (\abs{b} + \abs{c})^q \,d\rho
    \Big)^{p/q} \Big(\int \,d\rho\Big)^{1-p/q}
\end{align*}

Therefore we have the inclusion $\mathcal{B}_{q} \subset \mathcal{B}_p$ for $1
    \leq p \leq q \leq \infty$.
\end{proof}

As the reverse also holds in the class of ReLU functions,  we have
$\mathcal{B}_{\infty} = \mathcal{B}_p$, $\barronnorm{\cdot}{\infty} =
    \barronnorm{\cdot}{p}$  for all $1 \leq p \leq \infty$.

% ~\cite[Proposition 1]{eBarronSpaceFlowinduced2021}
\begin{proposition}
    \label{prop:equivalence_barron_space}

    For any $f \in \mathcal{B}_1$, $f \,\text{also}\, \in \mathcal{B}_{\infty}$
        and $\barronnorm{f}{\infty} = \barronnorm{f}{p}$ and hence $
        \mathcal{B}_{\infty} = \cdots = \mathcal{B}_{2} = \mathcal{B}_1$ when
        $\sigma(\cdot)$ is the ReLU function.
\end{proposition}

\begin{proposition}
    \label{prop:barron_space_is_banach}
    $\mcal{B}$ is a Banach space with norm $\norm{\cdot}_{\mcal{B}}$.
\end{proposition}

\begin{proof}
    See Theorem 2.3 in \cite[p. 7]{eRepresentationFormulasPointwise2020}.
\end{proof}

\section{Approximation rate in infinite-width Barron spaces}
\label{sec:approximation_in_infinite_width}

\begin{theorem} [Approximation in $\lp{2}$]\
    \label{thm:barron_direct_appro_l2}
    Let $U$ be a nonempty unbounded domain in $[0,1]^d$ and $f: U \to \R$. For
    any function $f \in \mathcal{B}(U)$ and any integer $n \in \Nat$, there
    exists a 2NN $f_n = f(x, \Theta) = \frac{1}{n}\sum_{j=1}^n a_j \sigma(b_j\tr
    x + c_j)$ such that
    \begin{equation}
        \norm{f - f_n}_{\lp{2}(U)}\lesssim \frac{\norm{f}_{\mathcal{B}}}{\sqrt{n}}.
    \end{equation}
    where $\Theta$ is the set of parameters $\Theta = \{(a_j, b_j, c_j),
    j=1,\dots,m\}$.

    % Furthermore, we have
    % \begin{equation}
    %     \norm{\Theta}_{\textnormal{path}} 
    %     := \frac{1}{n} \sum_{j=1}^m \abs{a_j} 
    %     (
    %         \norm{b_j}_1 + \abs{c_j}
    %     )
    %     \leq 3\norm{f}_{\mathcal{B}}
    % \end{equation}
\end{theorem}


\begin{proof}

Let $\epsilon >0$ and $\mu$ be a probability measure on $\Omega$ such that
\begin{align}
    &f(x) 
    = \ERWi{\mu}{a \sigma(b\tr x + c)} \\
    &\ERWi{\mu}{a^2 (\abs{b} + \abs{c})^2} 
    \leq (1+\epsilon) \norm{f}_{\mcal{B}}^2.
\end{align}

The second inequality means that the probability measure $\mu$ is chosen such
that this integral representation is \textbf{\textit{not}} the minimum over all
possible probability measures where the integral representation exists.

Let $\hat{f}_n(x)$ be the average drawn from the measure $\mu$, namely
\begin{equation}
    \hat{f}_n(x) := \frac{1}{n} \sum_{j=1}^n 
    a_j \sigma(b_j\tr x + c_j), \quad a_j, b_j, c_j \sim \mu.
\end{equation}

Next we would like to evaluate the approximation error between $f(x)$ and
$\hat{f}_n(x)$ on $x \in [0,1]^d$.

Let $e(\mu) = \ERWi{x}{\abs{\hat{f}_n(x) - f(x)}^2}$ and we evaluate the
expectation of approximation error
\begin{align}
    \ERWi{\mu}{e(\mu)} 
    &=
    \ERWi{\mu}{
        \ERWi{x}{
            \abs{\hat{f}_n(x) - f(x)}^2
        }
    } \\
    &= \ERWi{x}{
        \ERWi{\mu}{
            \abs{\hat{f}_n(x) - f(x)}^2
        }
    } \\
    &\leq \frac{1}{n^2} \sum_{j=1}^n \ERWi{x}{
        \ERWi{(a_j,b_j,c_j)\sim\mu}{ 
            \Big(a_j \sigma(b_j\tr x + c_j) - f(x)\Big)^2    
        }
    } \\
    &\leq \frac{1}{n} \ERWi{x}{
        \ERWi{(a,b,c)\sim\mu}{ 
            \Big(a \sigma(b\tr x + c)\Big)^2
        }
    } \\
    &= \frac{1}{n} \ERWi{\mu}{a^2 (\abs{b} + \abs{c})^2} 
    \leq \frac{(1+\epsilon)\norm{f}_{\mcal{B}}}{n}
\end{align}

Define the event $E = \{e(\mu) \leq C \norm{f}_{\mcal{B}}/n\}$, it is easy to
check
\begin{equation}
    \PR{E} = 1 - \PR{E^c} \geq 
    1 - \frac{\ERWi{\mu}{e(\mu)}}{C \norm{f}_{\mcal{B}}/n} =
    1 - \frac{1+\epsilon}{C} =
    \frac{C - 1 - \epsilon}{C}
\end{equation}

For any $C > 0$, we can find a corresponding $\epsilon$, and choose a 2NN with
parameter $\Theta$ satisfies the condition in the theorem.

\end{proof}



% The $\norm{\Theta}_{\textnormal{path}}$ is the per-unit norm control for 2NN
% defined in \cite{neyshaburNormBasedCapacityControl2015}. 

\begin{theorem}[Approximation in $\lp{\infty}$]
    Given the conditions outlined in Theorem \ref{thm:barron_direct_appro_l2},
    it can be established that for any function $f \in \mcal{B}(U)$ and any
    integer $n \in \Nat$, there exists a 2NN such that
    \begin{equation}
        \norm{f - f_n}_{\lp{\infty}(U)} \lesssim 
        \norm{f}_{\mathcal{B}} \sqrt{\frac{d+1}{n}}.
    \end{equation}
\end{theorem}

\begin{proof}
    For simplicity, we only prove the case where $U = I_d = [0,1]^d$. 
    Let $\mu$ be a probability measure on $\Sigma_{\Omega}$ where
    \eqref{eq:barron_represent} holds. Without loss of generality, we can assume
    $\norm{f}_{\mcal{B}} = \abs{a}$ almost everywhere on $\mu$ thanks to the
    homogeneity of ReLU function.

    A bound can found using Rademacher variables thanks to Lemma 26.2 in \cite[
    p. 376]{shalev-shwartzUnderstandingMachineLearning2014}

    Let $\xi$ be Rademacher variables, i.e. $\PR{\xi=1} = \PR{\xi=-1} =
    \frac{1}{2}$, we have
    \begin{equation}
        \label{eq:proof_l_infty_fouier_1}
        \ERWi{\mu}{\sup_{x\in I_d} 
        \frac{1}{n} \sum_{j=1}^n (a_j\sigma(b_j\tr x + c_j) - f(x))}
        \leq 
        2 \ERWi{\mu}{
            \frac{1}{n} 
            \ERWi{\xi}{
                \sum_{j=1}^n \sup \xi_j a_j\sigma(b_j\tr x + c_j)
            }
        }
    \end{equation}
    where $(a,b,c)\sim\mu$, and $\xi_j$ are Rademacher variables.

    We continue bounding the RHS
    \begin{align}
        &\ERWi{\xi}{
            \sup_{x\in I_d} \frac{1}{n}\sum_{j=1}^{n} \xi_j a_j\sigma(b_j\tr x + c_j)
        } \\
        &= \ERWi{\xi}{
            \sup_{x\in I_d} \frac{1}{n}\sum_{j=1}^{n} \xi_j \abs{a_j} \sigma(b_j\tr x + c_j)
        } \quad
        (\text{ symmetry of $\xi$}) \\
        &\leq \ERWi{\xi}{
            \sup_{x\in I_d} \frac{1}{n}\sum_{j=1}^{n} \xi_j \abs{a_j}(b_j\tr x + c_j)
        } \quad 
        (\text{ReLU}) \\
        &= \ERWi{\xi}{
            \sup_{x\in I_d} x'\tr \frac{1}{n}\sum_{j=1}^{n} \xi_j \abs{a_j}b_j'
        }
        \quad (b\tr x + c = b'\tr x') \\
        &= \ERWi{\xi}{\norm{
            \frac{1}{n} \sum_{j=1}^{n}\xi_j\abs{a_j}b_j'}_1
        }
    \end{align}

    Let $u = \abs{a} (\abs{b} + \abs{c})$,
    \begin{equation}
        \norm{u}_1 \leq \norm{f}_{\mcal{B}}      
    \end{equation}
    Then we can rewrite \eqref{eq:proof_l_infty_fouier_1} from the expectation
    w.r.t. all probability measure $\mu$ where $f(x) = \ERWi{\mu}{a \sigma(b\tr
    x + c)}$ holds to the supremum as below: 
    \begin{align}
        &\ERWi{\mu}{\sup_{x\in I_d} 
        \frac{1}{n} \sum_{j=1}^n (a_j\sigma(b_j\tr x + c_j) - f(x))} \\
        &\leq 2\ERWi{\mu}{
                \ERWi{\xi}{\norm{
                \frac{1}{n} \sum_{j=1}^{n}\xi_j \norm{u}_1}_1
            }
        } \\
        &= 2\sup_{\norm{u}_1 \leq \norm{f}_{\mcal{B}}} 
            \ERWi{\xi}{\norm{
                \frac{1}{n} \sum_{j=1}^{n}\xi_j\norm{u}_1}_1
            } \\
        &= 2\norm{f}_{\mcal{B}} \sup_{\norm{u}_1 \leq 1} 
            \ERWi{\xi}{\norm{
                \frac{1}{n} \sum_{j=1}^{n}\xi_j\norm{u}_1}_1
            } \\
        &= 2\norm{f}_{\mcal{B}} \sqrt{d+1} \sup_{\norm{u}_2 \leq 1} 
        \ERWi{\xi}{\norm{
            \frac{1}{n} \sum_{j=1}^{n}\xi_j\norm{u}_2}_2
        } \\
        &\leq 2\norm{f}_{\mcal{B}} \sqrt{\frac{d+1}{n}}
    \end{align}

    The last inequality follows the results of Rademacher variables in a bounded
    unit ball in a Hilbert space ($\abs{a}\abs{b'} \leq 1$). A proof can be
    found in Lemma 26.10 in \cite[p.
    383]{shalev-shwartzUnderstandingMachineLearning2014}
\end{proof}


\section{Connection with variation space}
\label{sec:infintie_width_variation_space}

In this section, we consider the $n$-term approximation using ReLU$^k$ functions
\begin{equation}
    \label{eq:reluk}
    \sigma_k(x) = [\max(0, x)]^k, \quad k \in \Nat^0
\end{equation}
when $k = 0$, $\sigma_0$ is the Heaviside function in Definition
\ref{eq:heaviside_represent}.

Similarly, an approximation upper bound using $n$ elements from the dictionary 
\begin{equation}
    \mathbb{D} = \{
        \sigma_k(b\tr x + b): b\in\R^d, c\in\R
    \} \quad k \in \Nat^0.
\end{equation}

It should be noted that the dictionary with ReLU\textsuperscript{0} function is
compact. However, the compactness of $\mathbb{D}^k$ when $k > 0$ is not
guaranteed so the Maurey's argument does not apply automatically. 

\begin{proposition}
    When $k > 0$, $\mathbb{D}^k$ is not compact in $\lp{p}(\Omega)$, $1 \leq p <
    \infty$.
\end{proposition}

To ensure the compactness of the dictionary, we limit the $b, c$ in the
following dictionary for $k>0$

\begin{equation}
    \label{eq:barron_dict}
    \mathbb{D}_{k} = \Bigg\{
        \sigma_k(b\tr x + c), \quad b\in S^{d-1}, c\in [c_1, c_2] 
    \Bigg\}
\end{equation}
where $\sigma_k$ is ReLU$^k$ function described above, $S^{d-1} := \{x\in\R^d:
\norm{x} = 1\}$ is the unit sphere in $\R^d$. $c_1, c_2$ is chosen such that
\begin{equation}
    c_1 < \inf_{x\in\Omega} b\tr x < 
    \sup_{x\in\Omega} b\tr x < c_2, \quad
    b \in S^{d-1}.
\end{equation}

The parameters $b$ and $c$ are restricted such that the set $\mathbb{D}_k$ is
bounded in $\lp{p}(\Omega)$.



\begin{proposition}
    Let $U$ be a nonempty bounded domain in $\R^d$ and $\mathbb{D}_1$ be the
    dictionary constructed in \eqref{eq:barron_dict}. The variation space
    constructed using $\mathbb{D}_1$ is equivalent to the
    \hyperref[def:barron_space]{infinite-width Barron space} $\mcal{B}(U)$:
    \begin{equation}
        \mcal{B}(U) = \spaceVar{\mathbb{D}_1}.
    \end{equation}
    
    Furthermore, the variation norm is equivalent to the Barron norm defined in
    \eqref{eq:barron_norm} up to some constant $C$ which is only dependent on
    the choice of $c_1, c_2$
    \begin{equation}
        \normVar{f}{\mathbb{D}_1} = \norm{f}_{\mcal{B}} \cdot C, \quad 
        C = C(c_1, c_2).
    \end{equation}
\end{proposition}

\begin{proof}

    \TODO

    This is Proposition 4. in \cite{siegelCharacterizationVariationSpaces2022}.

    We consider a dictionary
    \begin{equation}
        G = \{
            f
        \}
    \end{equation}

    Since B is compact set on $\lp{2}(U)$, it follows from Lemma
    \ref{lemma:compact_set_integral_representation} that there is Borel measure
    $\mu$ on $G$ such that 
    \begin{equation}
        f = \int_G \inclusionMap{G}{\lp{2}(U)} \,d\mu
    \end{equation}
    where $f$ is any function in the variation space on $\spaceVar{G}$.

    We can write the Barron norm of $f$ as the variation norm simply by changing
    $\mu = \abs{a}(\abs{b} + \abs{c}) \rho$:
    \begin{align*}
        \normVar{f}{G}
        &= \inf_{\mu} \Big\{ 
            \norm{\mu}_{G}: f = \int_G \inclusionMap{G}{\lp{2}(U)} \,d\mu
        \Big\} \\
        &= \inf_{\rho} \Big\{
            \int_{} \abs{a} (\abs{b} + \abs{c}) \,d\rho: 
            f = \int_{} a \sigma(b\tr x + c) \rho(\,da,\,db,\,dc)
        \Big\}
        = \norm{f}_{\mathcal{B}}.
    \end{align*}

    If functions are in the closed symmetric convex hull of $\mathbb{D}_1$, then
    they are in the variation space $\spaceVar{\mathbb{D}_1}$ by Proposition
    \ref{prop:spaceVar_properties}.

\end{proof}



% \subsection{Approximation in $L_{\infty}$ with bounded weights}

% We start with the main result when the approximation with 2NN with $m$ nodes and 
% the parameters bounded in $L_1$.

% \begin{theorem}
%     \label{thm:appro_bound_l1}
%     Let $U = [-1,1]^d$. Suppose $f: U \to \R$ admits a Fourier representation
%     and the spectral norm of order $2$ of $f$ is finite, i.e.
%     \begin{equation}
%         v_{f,2} = \int_{\R^d} \norm{\omega}_1^s \abs{\fourier{f}(\omega)} 
%         d\omega < \infty.
%     \end{equation}
%     There exists a 2NN of the form with ReLU activation function $\sigma$
%     \begin{equation}
%         f_n(x) = f(0) + \nabla f(0) \cdot x + v \cdot 
%         \frac{1}{n} \sum_{j=1}^n a_j \sigma(b_j\tr x + c_j)
%     \end{equation}
%     with $a_j\in[-1,1]$, $\norm{b_j}_1 = 1$, $c_j\in[0,1]$ and $v \leq
%     2v_{f,2}$ such that
%     \begin{equation}
%         \sup_{\mathbf{x} \in D} \norm{f(x) - f_m(x)}_{\infty} 
%         \leq c v_{f,2} \sqrt{d+\log{n}} \, n^{-1/2-1/d}
%     \end{equation}

%     for some universal $c > 0$.
% \end{theorem}

% \begin{theorem}
%     Let $U = [-1,1]^d$. Suppose $f: U \to \R$ admits a Fourier representation
%     and the spectral norm of order $2$ of $f$ is finite, i.e.
%     \begin{equation}
%         v_{f,3} = \int_{\R^d} \norm{\omega}_1^3 \abs{\fourier{f}(\omega)} 
%         d\omega < \infty.
%     \end{equation}
%     There exists a 2NN of the form with squared ReLU activation function
%     \begin{equation}
%         f_n(x) = f(0) + \nabla f(0) \cdot x + v \cdot 
%         \frac{1}{n} \sum_{j=1}^n a_j \sigma(b_j\tr x + c_j)
%     \end{equation}
%     with $a_j\in[-1,1]$, $\norm{b_j}_1 = 1$, $c_j\in[0,1]$ and $v \leq
%     2v_{f,2}$ such that
%     \begin{equation}
%         \sup_{\mathbf{x} \in D} \abs{f(x) - f_m(x)} \leq 
%         c v_{f,3} \sqrt{d} n^{-1/2-1/d}
%     \end{equation}

%     for some universal $c > 0$.
% \end{theorem}


 
% \section{Minimax Lower Bounds for Two Neural Network Model}

% For simplicity, data are of the form $\{(U_i, Y_i)\}_{i=1}^n$ from a

% For functions $f$ in the class $\mathcal{F}: [-1, 1]^d \to \mathcal{R}$, the
% minimax risk is:

% \begin{equation} R_{n,d} := \inf_{\hat{f}} \sup_{f\in \mathcal{F}}
%     \ERW{\norm{f - \hat{f}}^2} \end{equation}

% It has been shown in \TOCITE(Barron Minimax paper) that the minimax lower
% bound for neural nets is of order $\bigO(\log{d}/n)$ to some fractional power
% when $d$ is of larger order than $n$.

% \section{Risk Bounds for }

% {\itshape Firstly, I need to understand the difference between approximation
% rates and estimation of population risk.

% There exists a vast dictionary of definitions with similar wordings but the
% context is hughly different.

% e.g. What's the estimate of the population risk? In my understanding,

% $f^* - f_m$ where $f_m$ is the best solution in such hypothesis class is the
% approximation rates

% It should be that Population risk is w.r.t. a particular loss function?}

% \begin{equation} f(x) = \sum_{i=1}^m a_i \phi (\spr{\mathbf{w_i}}{x})
%     \end{equation}


\section{Improved rate}

We define the sets of functions whose coefficients $a_j$ are bounded in $\lp{1}$
and $\lp{\infty}$ for all $0 < n < \infty$.

\begin{align*}
    \Sigma_n^1(\mathbb{D}_k, M) &:= \Big\{
        \sum_{j=1}^n a_j d_j:
        d_j \in D^d_{\sigma_k}, \sum_{j=1}^n \norm{a_j}_1 \leq M 
    \Big\} \\
    \Sigma_n^{\infty}(\mathbb{D}_k, M) &:= \Big\{
        \sum_{j=1}^n a_j d_j:
        d_j \in D^d_{\sigma_k}, \max_{j} \abs{a_j} \leq M 
    \Big\}
\end{align*}


We will consider the cases where the $\lp{1}$-norm of $a_i$ is bounded or
unbounded.

\TONOTE{Theorems on the improved rates with its conditions}

\TONOTE{A summary table for all rates}

\subsection{Improved rate in classical Barron space through stricter conditions}

By imposing strict. Wait is the dictionary with Heaviside compact? w.r.t. a
metric?

\begin{theorem}\cite[Theorem 2, p. 218]{makovozUniformApproximationNeural1998}

    Let $U = [0,1]^d$ be the unit ball in $R^d$ and $f: U \to \R^d$ a function
    of the form
    \begin{equation}
        f(x) = \int_{S^d \times [-1,1]} c(b,c) H(b\tr x + b)\,d\mu
    \end{equation}
    where $c$ is in $\lp{\infty}(D, \mu)$ \TODO and $\norm{}_{\infty} \leq 1$, and $H$
    is the Heaviside function. Then for any $n \in \Nat$, there exists a linear
    combination in the form:
    \begin{equation}
        \label{eq:fn_Heaviside}
        f_n = \sum_{j=1}^n \frac{1}{n} a_j H(b_j\tr x + c_j), \quad
        a_j,c_j \in\R, b_j \in \R^d
    \end{equation}
    such that
    \begin{equation}
        \norm{f - f_n}_{\infty} \lesssim 
        n^{-\frac{1}{2} - \frac{1}{2d}} \sqrt{\log{n}}
    \end{equation}
\end{theorem}

\begin{corollary}
    \TONOTE{Add lp norm simply by lp space properties?}
\end{corollary}

\subsection{Improved rate in classical Barron space with less stricter conditions}

\begin{theorem}\cite[Theorem 4, p. 45]{maUniformApproximationRates2022} 
    
    Let $\mathbb{D}_0 = \{\sigma_0(b\tr x+c), b\in\R^d, c\in\R\}$. Let $f$ be
    any function from the closed convex hull of $\mathbb{D}_0$.  Then for any $n
    \in \Nat$, there exists a linear combination in the form
    \eqref{eq:fn_Heaviside} such that
    \begin{equation}
        \norm{f - f_n}_{\infty} \lesssim 
        n^{-\frac{1}{2} - \frac{1}{2d}}.
    \end{equation}

\end{theorem}

\begin{proof}
    Let $N = 2^l$ for some integer $l$. We consider a $f$ that can be
    represented as $f = \frac{1}{N}\sum_{j=1}^N H(b_j\tr x + c_j)$, which is
    clearly positive.

    Let $X=\{1,2,\cdots,N\}$ and $R_x$   be the index set of hyperplanes in $\R^d$
    \begin{equation}
        R_x = \{j: b_j\tr x+c_j \geq 0\}
    \end{equation}
    and $\mcal{R} = \{R_x: x\in\R^d\}$.

    From Theorem \ref{thm:coloring_set_bound}, we can find a coloring $\chi: X
    \to \{-1,+1\}$ of the set system $(X, \mcal{R})$
    \begin{equation}
        \label{eq:tmp_1}
        \abs{\sum_{j=1}^N \chi(j) H(b_j\tr x + c_j)} = 
        \abs{\sum_{j\in R_x} \chi(j)} \lesssim N^{\frac{1}{2}-\frac{1}{2d}}.
    \end{equation}

    Let $R_{+x} = \{i: b_j\tr x + c_j > 0\}$ and $R_{-x} = \{i: b_j\tr x + c_j <
    0\}$. The measure of $b_j\tr x + c_j = 0$ is zero for each $b_j, c_j$. It is
    easy to check that on $R_{+x} \bigcup R_{-x}$ 
    \begin{align}
        \abs{\sum_{j=1}^N \chi(j)} 
        &\leq \abs{\sum_{j\in R_{+x}} \chi(j)} + 
        \abs{\sum_{j\in\R_{-x}} \chi(j)} \\
        &\lesssim 2 N^{\frac{1}{2}-\frac{1}{2d}}.
    \end{align}

    From that we can conclude that we can find a balanced $\chi$ such that
    \eqref{eq:tmp_1} holds up to a constant $2$. A balanced coloring means that
    $\sum_{j=1}^N \chi(j) = 0$.

    Let $S$ be the set $\{i: \chi(i) = -1\}$ fulfilling \eqref{eq:tmp_1} and
    $\chi$ is a balanced coloring such that $\abs{S}=N/2$. Consequently, we can
    find 
    \begin{align}
        \abs{f - \frac{1}{\abs{S}}\sum_{j\in S}H(b_j\tr x+c_j)}
        &= \frac{1}{N} \abs{\sum_{j=1}^N\chi(j) H(b_j\tr x + c_j)} \\
        &= \frac{1}{N} \abs{\sum_{j\in R_x} \chi(j)} 
        \lesssim N^{-\frac{1}{2}- \frac{1}{2d}}.
    \end{align}

    It it clear that $\frac{1}{\abs{S}}\sum_{j\in S}H(b_j\tr x+c_j) \in
    \Sigma_{n.1}(\mathbb{D}_0)$. Setting $\abs{S} \in [\frac{n}{2}, n]$ yields the
    RHS of the theorem.

    The above results holds for general $f \in \closedConvexHull{\mathbb{D}_0}$
    since one can decompose $f$ into a convex combinations of negative and
    positive parts easily.
\end{proof}


\section{Difference and connection between different Barron spaces}
\label{sec:diff_barron_spaces}

This section will clarify the relationships between  Barron spaces, namely the
\textit{Fourier-analytic Barron spaces} and the \textit{infinite-width Barron
spaces}. Although some relationships between these spaces has been examined and
understood partially in
\cite{eBarronSpaceFlowinduced2021,eMathematicalUnderstandingNeural2020}, we hope
to clarify this problem in this section inspirerd by the work from
\cite{carageaNeuralNetworkApproximation2022}.

Firstly, Let $\Sigma_{\Omega}$ denote the set of all Borel probability
measures on $\Omega = \R^1 \times \R^d \times \R^1$ and we write functions that
admits the integral form
\begin{equation}
    \label{eq:integral_represent}
    f(x) = \int_{\omega} a\sigma(b\tr x + c) \,d\mu(a,b,c), \quad
    \forall x \in \R^d.
\end{equation}

Given a nonempty, bounded domain $U$ in $\R^d$, we have already defined various
Barron spaces:

\begin{itemize}
    \item $\bspace{\mcal{F}, s}$, $s \in \{1,2\}$ Fourier-analytic Barron spaces 
        \eqref{def:fourier_space} with $\norm{\cdot}_{\mcal{F},s}$ 
        \eqref{def:spectral_norm}
    \item $\mcal{B}$ infinite-width Barron spaces \eqref{def:barron_space} with
        $\norm{\cdot}_{\mcal{B}}$ \eqref{eq:barron_norm}
    {
        \setlength\itemindent{25pt}
        \item $\bspace{H}$ classical Barron space \eqref{def:heaviside_space}
            with $\norm{\cdot}_{\mcal{B}_H}$ \eqref{def:heaviside_norm}
    }
\end{itemize}

We \textit{could} include the classical Barron space within the infinite-width
Barron spaces when $\bspace{p}(U), p=0$ with a ReLU$^0$ activation function
which is essentially the Heaviside function but we decide against it to
emphasize on $\bspace{H}(U)$ as it is frequently visited. We denote
infinite-width Barron spaces with $\bspace{}(U)$ after the equivalence of
$\bspace{p}(U), 1\leq p \leq\infty$ has been shown in Proposition
\ref{prop:equivalence_barron_space}.

% hookrightarrow or subset
\begin{proposition}
    Given the constructions of spaces above and a nonempty bounded domain $U$ in
    $\R^d$, the following relationships holds:

    1) $\mcal{B}(U) \subset \bspace{H}(U)$

    2) $\bspace{\mathcal{F}, 1}(U) \subset \bspace{H}(U)$

    3) $\bspace{\mathcal{F}, 2}(U) \subset \mcal{B}(U)$
\end{proposition}


\begin{proof}

% As shown in weinan, functions in the $\mathcal{B}_{ReLU}$ i.e. Barron space, are
% Lipschitz.

% https://math.stackexchange.com/questions/2319301/why-must-bounded-sets-be-contained-within-a-closed-ball
\textbf{1):} 
One can begin with the connection between the ReLU and the Heaviside function.
As $U$ is nonempty and bounded in $\R^d$, there is a open ball for some $x \in
\R^d$, $B_r(\cdot)$, with a radius $\delta > 0$ whose closure contains $U$ such
that
\begin{equation}
    U \subset \closure{B_{\delta}(x)}.
\end{equation}

For $x=0$ and a suitable $\delta$, $U \subset \closure{B_{\delta}(0)}$ then we
have:

\begin{equation}
    \sigma(x) = \int_0^{1+\delta} H(x-t) \,dt 
    \quad \forall x \in \R \textnormal{ and } \abs{x} < \delta.
\end{equation}

Let $\beta_{b,c}$ be $\abs{b} + \abs{c}$ for any $b\in\R^d, c\in\R$. It is easy
to see that $\abs{b\tr x + c} \leq (1+\delta)\beta_{b,c}$. Thanks to the
positive homogeneity of ReLU function $\sigma$, i.e. $\sigma(\lambda x) =
\lambda \sigma(x)$ for $x \in \R$, we observe that any function $f:U\to\R$ that
admits such an integral representation with a measure $\mu \in \Sigma_{\Omega}$
can be rewritten as
\begin{align*}
    f(x) 
    &= \int_{\Omega} a \sigma(b\tr x + c )\,d\mu(a,b,c) \\
    &= \int_{\Omega} \beta_{b,c} \sigma(
        \frac{b\tr x}{\beta_{b,c}}+ \frac{c}{\beta_{b,c}}
    ) \,d\mu(a,b,c) \\
    &= \int_{\Omega} \int_0^{1+\delta} 
        a\beta_{b,c} H(\frac{b\tr x}{\beta_{b,c}} +
        \frac{c}{\beta_{b,c}} -t)\,dt\,d\mu(a,b,c) \quad
        \text{(Fubini's Theorem)} \\
    &= \int_{\Omega} a' H(b\tr x + c') \,d\nu(a',b,c'), 
    \quad \forall x \in U
\end{align*}
where $a', c' \in \R$ for some $v \in \Sigma_{\Omega}$.

The inclusion is immediate if one can find a measure $v$ and the integral
condition $r(f, v, H)$ is also finite.

With a mapping
\begin{equation}
    T: \Omega \times [0,1+\delta] \to \Omega, \quad 
    ((a,b,c), t) \mapsto
    (a\beta_{b,c}, \frac{b}{\beta_{b,c}}, \frac{c}{\beta_{b,c}} - t)
\end{equation}

 we can construct the measure $v$ via the pushforward of the product measure
$\mu\otimes\lambda$, given $\lambda$ is the Lebesgue measure on the interval
$[0,1+\delta]$,
\begin{equation}
    v := T^{-1}(\mu\otimes\lambda).
\end{equation}

Furthermore, we can evaluate the $r(f, v, H)$
\begin{align}
    r(f, v, H) 
    &= \int_{\Omega} \abs{a} \,dv(a,v,c) 
    = \int_{\Omega}\int_0^{1+\delta} \abs{a\beta_{b,c}} \,dt\,d\mu(a,b,c) \\
    &= (1+\delta) \abs{a}(\abs{b} + \abs{c}) \,d\mu(a,b,c)
    = (1+\delta) r(f,\mu) < \infty.
\end{align}

Therefore, it shows that for any function $f \in \mcal{B}(U)$
\begin{equation}
    \norm{f}_{\mathcal{B}_H} \lesssim \norm{f}_{\mcal{B}} < \infty
\end{equation}
hence the inclusion holds.

\textbf{2):} This is a direct consequence of \cite[Theorem
2]{barronNeuralNetApproximation1992}.

% and we include the proof for completeness.

% \begin{theorem}
%     Let $f$ be a function that admits a Fourier representation with finite
%     spectral norm of order $1$, i.e.
%     \begin{equation}
%         v_{f,1} < \infty
%     \end{equation}
%     then $f(x) - f(0)$ can be expressed as an infinite convex combination of
%     indicator multiplied by a constant
%     \begin{equation}
%         f(x) - f(0) = \int_{\R^d}\int_0^1 (
%             \indicator{} - \indicator{}
%         ) \,d\omega\,dt
%     \end{equation}
% \end{theorem}

% By Fourier transform, note that
% \begin{equation}
%     f(x) - f(0) = \int (e^{i\omega\tr x} - 1) \fourier{f}(\omega)\,d\omega
% \end{equation}

% We also have
% \begin{equation}
%     e^{iz} - 1 =
%     \begin{cases}
%         i \int_0^c \indicator{\{z>u\}} e^{iu} \,du \quad
%             &\text{ when } z \in [0,c] \\
%         -i \int_0^c \indicator{\{z<-u\}} e^{iu} \,du \quad
%             &\text{ when } z \in [c,0] 
%     \end{cases}
% \end{equation}

% It follows that
% \begin{equation}
%     e^{iz} - 1 = i \int_0^c (
%         \indicator{\{z>u\}} - \indicator{\{z<-u\}}  
%     )
%     e^{iu} \,du 
% \end{equation}

% Integrating when $z = \omega x$ and $c=\abs{\omega}_{[0,1]}$ defined in
% \eqref{def:fourier_class} gives
% \begin{equation}
%     f(x) -f(0) = i\int_{\R^d} (\int_0^{c} (
%         \indicator{\{\omega x>u\}} - \indicator{\{\omega x<-u\}}
%     ) e^{iu}\,du)
%     \fourier{f}(\omega)\,d\omega
% \end{equation}

% Only taking the real part of the LHS and RHS and integrating using Fubini's theorem
% \begin{equation}
%     f(x) = f(0) + \int_{\R^d} \int_0^1 (
%         \indicator{\{\omega x<-t\}} - \indicator{\{\omega x>t\}}
%     ) \abs{\omega} \sin(t\omega + \theta_{\omega})
%     \fourier{f}(\omega)\,d\omega\,d\omega
% \end{equation}

% A similar argument as the proof in \TONOTE{proof of Fourier} is employed here
% where the ``drawing'' parameters from the distribution shows that the $f(x) -
% f(0)$ is the closure of the convex hull of finite linear combinations.

% Hence we show the inclusion in 2).

\textbf{3):} As $U$ is nonempty and bounded in $\R^d$, we can fix a point $x_0
\in \R^d$ and a radius $\delta > 0$ such that $U \subset x_0 + [0,\delta]^d$.
Without loss of generality, it is safe to assume that $f$ is a function in
$\mathcal{B}_{\mathcal{F},2}$ with the spectral condition $v_{f,2}\leq 1$
\eqref{def:spectral_seminorm}. This implies \hyperref[def:spectral_norm]{spetral
norm} $\norm{f}_{\bspace{\mcal{F}, 2}} \leq 2$ by direct calculation. 

One can prove the inclusion if $f$ can be represented as in
\eqref{eq:integral_represent} with a measure in $\Sigma_{\Omega}$.

We define two mapping $G, H: \R^d \to \mathbb{C}$:
\begin{align*}
    G(\omega) &= \frac{1}{2} (\fourier{f}(\omega) 
                    + \overline{\fourier{f}(-\omega)}) \\
    H(\omega) &= \frac{1}{\delta^d} \cdot 
                    e^{\frac{i \omega\tr x_0}{\delta}} \cdot 
                    G(\omega / \delta)
\end{align*}
where $\fourier{f}$ is the Fourier transform of $f$ and $\overline{\fourier{f}}$
is the complex conjugate of $\fourier{f}$.

We calculate their respective spectral norm in $\bspace{\mcal{F}, 2}$:
\begin{align}
    \norm{G}_{\mathcal{F},2} &\leq 2 \\
    \norm{H}_{\mathcal{F},2} &\leq 2\delta^2
\end{align}

We then define two functions from $U$ to $\R$ with $G,H$ as their Fourier
transform, respectively.
\begin{align*}
    g(x) &:= \int_{\R^d} e^{i\omega\tr x} G(\omega)\,d\omega\\
    h(x) &:= \int_{\R^d} e^{i\omega\tr x} H(\omega)\,d\omega\\
\end{align*}
It is easy to check that for all $x \in U$, $f(x)=g(x)=h(\frac{x-x_0}{\delta})$.

By construction, the spectral condition of $h$, $v_{h,2}$, is finite. We have
$\norm{h}_{\mathcal{B}}$ is finite with some constant $C_h$ thanks to Theorem 9
in \cite{eMathematicalUnderstandingNeural2020}. Therefore, $h(y)$ can be
represented as
\begin{equation}
    h(y) = \int_{[0,1]^d} a \sigma(b\tr x + c) \,d\mu(a,b,c) \quad
    \forall y \in [0,1]^d
\end{equation}
where $\mu \in \Sigma_{\Omega}$ and $\norm{f}_{\mcal{B}} < \infty$ w.r.t. some
constant only dependent on $\delta$ and $d$.

Since $y=\frac{x-x_0}{\delta}$ for all $x\in U$, the results above implies that 
\begin{equation}
    f(x) = h(\frac{x-x_0}{\delta}) \int_{\Omega} a 
    \sigma(\frac{b\tr x}{\delta} + c - \frac{b\tr x_0}{\delta})\,dv(a,b,c)
\end{equation}
for some measure $v \in \Sigma_{\Omega}$.

We continue the construction of measure via the pushforward of $v = T(\mu)$. Let
$T$ be a mapping:
\begin{equation}
    T: \Omega \to \Omega, \quad
    (a,b,c) \mapsto (a, \frac{b}{\delta}, c - \frac{b\tr x_0}{\delta})
\end{equation}

By calculation, $r(f, v) \leq (1+\abs{x_0}) r(h, \mu)$ is finite w.r.t some
constant $C$ dependent only on $d,\delta,x_0$. Hence the inclusion is shown.

\end{proof}


\begin{proposition}

    Let $U \subset \mathbb{R}^d$ be bounded and have nonempty interior. For
    $s>0$, if $\mathcal{B}_{\mathcal{F},s}(U) \subset \mathcal{B}_{1}(U)$, then
    $s \geq 2$. In particular $\mathcal{B}_{\mathcal{F},1}(U) \not\subset
    \mathcal{B}_{1}(U)$.
\end{proposition}

\begin{remark}

    It has been argued in Theorem 3.1 \cite[p.
    12]{eRepresentationFormulasPointwise2020} that $\bspace{\mcal{F},1}$ embeds
    into the $\mcal{B}$ but \cite{carageaNeuralNetworkApproximation2022} proven
    that this embedding wrongly interpreted the results of
    \cite{barronUniversalApproximationBounds1993,barronNeuralNetApproximation1992}.
    In other words, the original model class (i.e. $\bspace{\mcal{F},1}$)
    proposed by \cite{barronNeuralNetApproximation1992} is not
    \textit{contained} or \textit{embeded} in the novel Barron space $\mcal{B}$
    introduced recently by \cite{eBarronSpaceFlowinduced2021}. 
    
    % It has been discussed in earlier section that we have the equivalence of
    % Barron norm and Barron spaces for $1 \leq p\leq +\infty$ (see
    % \eqref{eq:barron_fouier_int}) with ReLU as activation function.

    One can observe that the class of functions in which $f$ admits a Fourier
    representation with finite \textit{second} moment, $\bspace{\mcal{F}, 2}$,
    is well contained inside the \textit{infinite-width Barron space}. However,
    $\mathcal{B}_{\mathcal{F}, 1}$ still encapsulates a boarder class of
    functions. In other words, the infinite-width Barron space $\mcal{B}$ is
    \textit{sandwiched} between $\bspace{\mcal{F}, 1}$ and $\bspace{\mcal{F},
    2}$.
\end{remark}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "MasterThesisSfS"
%%% End: 
